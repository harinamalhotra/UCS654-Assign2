{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udvh8Nzlc3-F",
        "outputId": "4bbfd7f8-b445-4c29-c11a-8e870cb58747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution:\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "data_url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "df = pd.read_csv(data_url)\n",
        "\n",
        "print(\"Original class distribution:\")\n",
        "print(df[\"Class\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[\"Class\"])\n",
        "y = df[\"Class\"]\n",
        "\n",
        "oversampler = RandomOverSampler(random_state=1)\n",
        "X_bal, y_bal = oversampler.fit_resample(X, y)\n",
        "\n",
        "balanced_data = pd.concat([X_bal, y_bal], axis=1)\n",
        "\n",
        "print(\"\\nBalanced class distribution:\")\n",
        "print(balanced_data[\"Class\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i5OVwQ8c_z9",
        "outputId": "05db1515-82c7-4659-f4ba-ad9797df14f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Balanced class distribution:\n",
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(balanced_data)\n",
        "error_rate = 0.05\n",
        "sample_size = int(N / (1 + N * (error_rate ** 2)))\n",
        "\n",
        "print(\"Calculated sample size:\", sample_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cYJgdywdC-t",
        "outputId": "b1981e08-3138-4898-c2f5-1c6705a318eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated sample size: 316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#simple random sampling\n",
        "def random_sample(df, size):\n",
        "    return df.sample(n=size, random_state=42)\n"
      ],
      "metadata": {
        "id": "Hl9n91K5dFyz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#systematic sampling\n",
        "def systematic_sample(df, size):\n",
        "    interval = len(df) // size\n",
        "    idx = np.arange(0, len(df), interval)\n",
        "    return df.iloc[idx[:size]]\n"
      ],
      "metadata": {
        "id": "IBmHJtjDdL1Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stratified sampling\n",
        "def stratified_sample(df, size):\n",
        "    per_class = size // df[\"Class\"].nunique()\n",
        "    return df.groupby(\"Class\", group_keys=False).apply(\n",
        "        lambda x: x.sample(min(len(x), per_class), random_state=42)\n",
        "    )\n"
      ],
      "metadata": {
        "id": "A-OHKnbudSSz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cluster sampling\n",
        "def cluster_sample(df):\n",
        "    df_temp = df.copy()\n",
        "    df_temp[\"cluster\"] = pd.cut(df_temp[\"V1\"], bins=10, labels=False)\n",
        "\n",
        "    while True:\n",
        "        chosen = np.random.choice(df_temp[\"cluster\"].unique())\n",
        "        subset = df_temp[df_temp[\"cluster\"] == chosen]\n",
        "        if subset[\"Class\"].nunique() > 1:\n",
        "            return subset.drop(columns=[\"cluster\"])\n"
      ],
      "metadata": {
        "id": "_etyrVWIdXz_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bootstrap sampling\n",
        "def bootstrap_sample(df, size):\n",
        "    return df.sample(n=size, replace=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "n4PJllFedeMq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating 5 samples\n",
        "sample_sets = {\n",
        "    \"Sampling1_Random\": random_sample(balanced_data, sample_size),\n",
        "    \"Sampling2_Systematic\": systematic_sample(balanced_data, sample_size),\n",
        "    \"Sampling3_Stratified\": stratified_sample(balanced_data, sample_size),\n",
        "    \"Sampling4_Cluster\": cluster_sample(balanced_data),\n",
        "    \"Sampling5_Bootstrap\": bootstrap_sample(balanced_data, sample_size)\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEyll6k5djt4",
        "outputId": "30776627-0825-4cb9-a11d-933fb3678fa3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1708318849.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby(\"Class\", group_keys=False).apply(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining 5 ML models\n",
        "models = {\n",
        "    \"M1_Logistic\": LogisticRegression(max_iter=1000),\n",
        "    \"M2_DecisionTree\": DecisionTreeClassifier(),\n",
        "    \"M3_RandomForest\": RandomForestClassifier(),\n",
        "    \"M4_SVM\": SVC(),\n",
        "    \"M5_KNN\": KNeighborsClassifier()\n",
        "}\n"
      ],
      "metadata": {
        "id": "UsGH7ILJdrZx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results = {}\n",
        "\n",
        "for sample_name, sample_df in sample_sets.items():\n",
        "    X_sample = sample_df.drop(columns=[\"Class\"])\n",
        "    y_sample = sample_df[\"Class\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_sample, y_sample, test_size=0.2, random_state=42, stratify=y_sample\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    final_results[sample_name] = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        if model_name in [\"M1_Logistic\", \"M4_SVM\", \"M5_KNN\"]:\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            predictions = model.predict(X_test_scaled)\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, predictions)\n",
        "        final_results[sample_name][model_name] = round(acc * 100, 2)\n",
        "accuracy_df = pd.DataFrame(final_results)\n",
        "print(\"\\nAccuracy Table:\")\n",
        "print(accuracy_df)\n",
        "print(\"\\nBest Sampling Technique for each Model:\")\n",
        "print(accuracy_df.idxmax(axis=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JypWNxNAdzXt",
        "outputId": "d8c95bd5-2d86-4491-ee6f-1ee60005f4e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy Table:\n",
            "                 Sampling1_Random  Sampling2_Systematic  Sampling3_Stratified  \\\n",
            "M1_Logistic                 84.38                 85.94                 90.62   \n",
            "M2_DecisionTree             92.19                 96.88                 96.88   \n",
            "M3_RandomForest            100.00                100.00                100.00   \n",
            "M4_SVM                      90.62                 93.75                 98.44   \n",
            "M5_KNN                      90.62                 85.94                 92.19   \n",
            "\n",
            "                 Sampling4_Cluster  Sampling5_Bootstrap  \n",
            "M1_Logistic                  100.0                92.19  \n",
            "M2_DecisionTree              100.0               100.00  \n",
            "M3_RandomForest              100.0               100.00  \n",
            "M4_SVM                       100.0               100.00  \n",
            "M5_KNN                       100.0                98.44  \n",
            "\n",
            "Best Sampling Technique for each Model:\n",
            "M1_Logistic        Sampling4_Cluster\n",
            "M2_DecisionTree    Sampling4_Cluster\n",
            "M3_RandomForest     Sampling1_Random\n",
            "M4_SVM             Sampling4_Cluster\n",
            "M5_KNN             Sampling4_Cluster\n",
            "dtype: object\n"
          ]
        }
      ]
    }
  ]
}